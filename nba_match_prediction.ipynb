{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c79d1a7b",
   "metadata": {},
   "source": [
    "# NBA Match Prediction\n",
    "## By Shy Ohev Zion and Aviram Shabtai\n",
    "\n",
    "**Disclaimer** - This notebook is based on [Berkay YALCIN](https://www.kaggle.com/yalcinberkay)'s [work](https://www.kaggle.com/code/yalcinberkay/nba-match-prediction-result-points/notebook)\n",
    "- While the base notebook uses Pandas and SKLearn for data manipulation and machine learning respectively, <br>\n",
    "    our code uses PySpark for both, with the addition of Kafka for data streaming.\n",
    "- The differences in libraries and methodologies also encouraged us to create better functions and tools <br>\n",
    "    (e.g. a model pipeline to apply regression to all 8 regression columns in one go) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11ee681",
   "metadata": {},
   "source": [
    "### TL;DR\n",
    "In this notebook, a dataset of NBA games from 2012-2019 is used to create a 'model set' to predict a game's results - each team's score in every quarter. the set is made up of 8 different models, for each quarter for the two teams\n",
    "\n",
    "The results are not up to the standards we set to ourselves and can be improved, but do demonstrate the use of the technologies learned during the course."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29187df6",
   "metadata": {},
   "source": [
    "## 1. Initial Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce525af",
   "metadata": {},
   "source": [
    "### Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04b5c8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base python\n",
    "from time import sleep\n",
    "from io import StringIO\n",
    "from pathlib import Path\n",
    "from threading import Thread\n",
    "\n",
    "# Spark imports\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.regression import GBTRegressor, GBTRegressionModel\n",
    "from pyspark.ml.evaluation import RegressionEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import (\n",
    "    StringIndexer,\n",
    "    StandardScaler,\n",
    "    OneHotEncoder,\n",
    "    VectorAssembler,\n",
    ")\n",
    "\n",
    "# Kafka imports\n",
    "from confluent_kafka import Producer, Consumer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c29bba",
   "metadata": {},
   "source": [
    "### Paths and Directories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c0b0be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = Path(\"input\")\n",
    "matches_path = input_path / \"matches_w_player_stats.csv\"\n",
    "processed_input_path = input_path / \"preprocessed_matches\"\n",
    "\n",
    "preprocessing_pipeline_path = Path(\"preprocessing_pipeline\")\n",
    "model_path = Path(\"models\")\n",
    "model_pipeline_path = model_path / \"pipeline\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a623304b",
   "metadata": {},
   "source": [
    "### Data Column Organization:\n",
    "\n",
    "The given [dataset](https://www.kaggle.com/datasets/yalcinberkay/nba-matches-dataset-w-player-stats) was taken from https://www.nba.com/stats by the original notebook's author (the meaning of each column can be read [here](https://www.nba.com/stats/help/glossary).<br>\n",
    "The following code cell includes all of the columns in the dataset and sorts them to 3 types:\n",
    "\n",
    "- ```numerical_cols```\n",
    "- ```categorical_cols```- columns that need to be converted to numeric columns, which is done using indexation and one-hot encoding\n",
    "- ```non_informative_cols``` - as the name implies, these columns provide no extra information and are useless in the match result prediction (e.g. game result is derived from the final scores, which in turn are the sum of the scores in each quarter)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd99b8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of player-related columns\n",
    "player_cols = [\n",
    "    \"PLAYER_NAME\",\n",
    "    \"MIN\",\n",
    "    \"FGM\",\n",
    "    \"FGA\",\n",
    "    \"FG_PCT\",\n",
    "    \"FG3M\",\n",
    "    \"FG3A\",\n",
    "    \"FG3_PCT\",\n",
    "    \"FTM\",\n",
    "    \"FTA\",\n",
    "    \"FT_PCT\",\n",
    "    \"OREB\",\n",
    "    \"DREB\",\n",
    "    \"REB\",\n",
    "    \"AST\",\n",
    "    \"STL\",\n",
    "    \"BLK\",\n",
    "    \"TO\",\n",
    "    \"PF\",\n",
    "    \"PTS\",\n",
    "    \"PLUS_MINUS\",\n",
    "]\n",
    "\n",
    "team_player_cols = [f\"TEAM_{col}_{i}\" for i in range(1, 11 + 1) for col in player_cols]\n",
    "\n",
    "oppt_player_cols = [f\"OPPT_{col}_{i}\" for i in range(1, 11 + 1) for col in player_cols]\n",
    "\n",
    "# List of team-related columns\n",
    "team_cols = [\n",
    "    \"gameId\",\n",
    "    \"teamAbbr\",\n",
    "    \"opptAbbr\",\n",
    "    \"result\",\n",
    "    \"teamMin\",\n",
    "    \"teamPTS\",\n",
    "    \"teamPTS1\",\n",
    "    \"teamPTS2\",\n",
    "    \"teamPTS3\",\n",
    "    \"teamPTS4\",\n",
    "    \"opptPTS\",\n",
    "    \"opptPTS1\",\n",
    "    \"opptPTS2\",\n",
    "    \"opptPTS3\",\n",
    "    \"opptPTS4\",\n",
    "    \"teamFGM\",\n",
    "    \"teamFGA\",\n",
    "    \"teamFG\",\n",
    "    \"team3PM\",\n",
    "    \"team3PA\",\n",
    "    \"team3PCT\",\n",
    "    \"teamFTM\",\n",
    "    \"teamFTA\",\n",
    "    \"teamFTC\",\n",
    "    \"teamORB\",\n",
    "    \"teamDRB\",\n",
    "    \"teamREB\",\n",
    "    \"teamAST\",\n",
    "    \"teamSTL\",\n",
    "    \"teamBLK\",\n",
    "    \"teamTO\",\n",
    "    \"teamPF\",\n",
    "    \"team2P\",\n",
    "    \"teamTS\",\n",
    "    \"teamEFG\",\n",
    "    \"teamPPS\",\n",
    "    \"teamFIC\",\n",
    "    \"teamFIC40\",\n",
    "    \"teamOrtg\",\n",
    "    \"teamDrtg\",\n",
    "    \"teamPlay\",\n",
    "]\n",
    "# List of opponent team-related columns\n",
    "oppt_cols = [\n",
    "    \"opptMin\",\n",
    "    \"opptFGM\",\n",
    "    \"opptFGA\",\n",
    "    \"opptFG\",\n",
    "    \"oppt3PM\",\n",
    "    \"oppt3PA\",\n",
    "    \"oppt3PCT\",\n",
    "    \"opptFTM\",\n",
    "    \"opptFTA\",\n",
    "    \"opptFTC\",\n",
    "    \"opptORB\",\n",
    "    \"opptDRB\",\n",
    "    \"opptREB\",\n",
    "    \"opptAST\",\n",
    "    \"opptSTL\",\n",
    "    \"opptBLK\",\n",
    "    \"opptTO\",\n",
    "    \"opptPF\",\n",
    "    \"oppt2P\",\n",
    "    \"opptTS\",\n",
    "    \"opptEFG\",\n",
    "    \"opptPPS\",\n",
    "    \"opptFIC\",\n",
    "    \"opptFIC40\",\n",
    "    \"opptOrtg\",\n",
    "    \"opptDrtg\",\n",
    "    \"opptPlay\",\n",
    "]\n",
    "\n",
    "last_cols = [\"poss\", \"LM_totalPoint\", \"LM_dayOffset\", \"pace\"]\n",
    "\n",
    "matchup_cols = team_cols + team_player_cols + oppt_cols + oppt_player_cols + last_cols\n",
    "\n",
    "# List of columns that are not informative for the modeling process\n",
    "non_informative_cols = [\n",
    "    \"gameId\",\n",
    "    \"result\",\n",
    "    \"opptPTS\",\n",
    "    \"teamPTS\",\n",
    "] + [col for col in matchup_cols if \"PLAYER_NAME\" in col]\n",
    "\n",
    "categorical_cols = [\"teamAbbr\", \"opptAbbr\"]\n",
    "\n",
    "# List of columns to be used in regression analysis\n",
    "regression_cols = [\n",
    "    \"teamPTS1\",\n",
    "    \"teamPTS2\",\n",
    "    \"teamPTS3\",\n",
    "    \"teamPTS4\",\n",
    "    \"opptPTS1\",\n",
    "    \"opptPTS2\",\n",
    "    \"opptPTS3\",\n",
    "    \"opptPTS4\",\n",
    "]\n",
    "\n",
    "numerical_cols = list(\n",
    "    set(matchup_cols).difference(\n",
    "        non_informative_cols + categorical_cols + regression_cols\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c37b5d0",
   "metadata": {},
   "source": [
    "## 2. Data and Model Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f89ceb",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "As the matches are from 2012-2019, minor changes are required:\n",
    "1. Update the abbreviations of teams that have changed their names.\n",
    "1. Remove rows containing teams that are no longer active."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9ec79a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_abbrs_and_remove_closed_teams(df):\n",
    "    updated_teams = {\"NJN\": \"BKN\", \"NOH\": \"NOP\"}\n",
    "\n",
    "    for old, new in updated_teams.items():\n",
    "        df = df.withColumn(\"teamAbbr\", F.regexp_replace(\"teamAbbr\", old, new))\n",
    "        df = df.withColumn(\"opptAbbr\", F.regexp_replace(\"opptAbbr\", old, new))\n",
    "    closed_teams = [\"EST\", \"FLA\", \"GNS\", \"GUA\", \"MAC\"]\n",
    "\n",
    "    for team in closed_teams:\n",
    "        df = df.filter((F.col(\"opptAbbr\") != team) & (F.col(\"teamAbbr\") != team))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df7b88e",
   "metadata": {},
   "source": [
    "### Preprocessing Pipeline Creation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9154b76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_assembler = VectorAssembler(\n",
    "    inputCols=numerical_cols, outputCol=\"numericalFeatures\", handleInvalid=\"skip\"\n",
    ")\n",
    "\n",
    "scaler = StandardScaler(\n",
    "    inputCol=numerical_assembler.getOutputCol(), outputCol=\"scaledFeatures\"\n",
    ")\n",
    "\n",
    "indexers = [\n",
    "    StringIndexer(inputCol=c, outputCol=f\"{c}_indexed\") for c in categorical_cols\n",
    "]\n",
    "\n",
    "encoders = [\n",
    "    OneHotEncoder(\n",
    "        inputCol=idxr.getOutputCol(), outputCol=f\"{idxr.getOutputCol()}_encoded\"\n",
    "    )\n",
    "    for idxr in indexers\n",
    "]\n",
    "\n",
    "categorical_assembler = VectorAssembler(\n",
    "    inputCols=[enc.getOutputCol() for enc in encoders], outputCol=\"categoricalFeatures\"\n",
    ")\n",
    "\n",
    "final_assembler = VectorAssembler(\n",
    "    inputCols=[scaler.getOutputCol(), categorical_assembler.getOutputCol()],\n",
    "    outputCol=\"features\",\n",
    ")\n",
    "\n",
    "preprocessing_pipeline = Pipeline(\n",
    "    stages=[numerical_assembler]\n",
    "    + [scaler]\n",
    "    + indexers\n",
    "    + encoders\n",
    "    + [categorical_assembler]\n",
    "    + [final_assembler]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800f49a6",
   "metadata": {},
   "source": [
    "### Data Fuctions:\n",
    "```create_training_data``` - reads the raw match data, fits the pipeline to the data, preprocesses it using the fitted pipeline model, saves the preprocessed data and the model, and finally returns both.\n",
    "\n",
    "```load_training_data``` - reads the preprocessed match data from a Parquet file (not a CSV, as one of the columns is a ```Vector```) and loads the preprocessing pipeline model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d58183a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_data():\n",
    "    _matches = spark.read.csv(str(matches_path), inferSchema=True, header=None).toDF(\n",
    "        *matchup_cols\n",
    "    )\n",
    "    _matches = update_abbrs_and_remove_closed_teams(_matches)\n",
    "\n",
    "    _preprocessing_pipeline_model = preprocessing_pipeline.fit(_matches)\n",
    "\n",
    "    _preprocessing_pipeline_model.write().overwrite().save(\n",
    "        str(preprocessing_pipeline_path)\n",
    "    )\n",
    "\n",
    "    _matches = _preprocessing_pipeline_model.transform(_matches).select(\n",
    "        non_informative_cols + categorical_cols + regression_cols + [\"features\"]\n",
    "    )\n",
    "\n",
    "    _matches.write.save(str(processed_input_path), mode=\"overwrite\")\n",
    "\n",
    "    return _matches, _preprocessing_pipeline_model\n",
    "\n",
    "\n",
    "def load_training_data():\n",
    "    _matches = spark.read.parquet(str(processed_input_path), inferSchema=True)\n",
    "    _preprocessing_pipeline_model = PipelineModel.load(str(preprocessing_pipeline_path))\n",
    "\n",
    "    return _matches, _preprocessing_pipeline_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf99aa9",
   "metadata": {},
   "source": [
    "### Model Functions\n",
    "```create_models``` - creates and trains 8 different regressors for each of the regression columns (as mensioned above, one for each team score in every quarter), and creates a pipeline for streamlining the prediction process - one transformation instead of applying 8 different ones in a row. \n",
    "\n",
    "```load_models``` - loads the created regressors and pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33d4c25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_models(train_df):\n",
    "    _models = dict()\n",
    "\n",
    "    for reg_col in regression_cols:\n",
    "        regressor = GBTRegressor(\n",
    "            labelCol=reg_col,\n",
    "            featuresCol=\"features\",\n",
    "            predictionCol=f\"{reg_col}_prediction\",\n",
    "        )\n",
    "\n",
    "        paramGrid = (\n",
    "            ParamGridBuilder()\n",
    "            .addGrid(regressor.maxDepth, [2, 4, 6])\n",
    "            .addGrid(regressor.maxBins, [20, 30])\n",
    "            .addGrid(regressor.maxIter, [10, 20])\n",
    "            .build()\n",
    "        )\n",
    "\n",
    "        cv = CrossValidator(\n",
    "            estimator=regressor,\n",
    "            estimatorParamMaps=paramGrid,\n",
    "            evaluator=RegressionEvaluator(\n",
    "                labelCol=regressor.getLabelCol(),\n",
    "                predictionCol=regressor.getPredictionCol(),\n",
    "            ),\n",
    "            numFolds=5,\n",
    "        )\n",
    "\n",
    "        cvModel = cv.fit(train_df)\n",
    "\n",
    "        cvModel.bestModel.write().overwrite().save(str(model_path / reg_col))\n",
    "\n",
    "    _regression_pipeline_model = PipelineModel(\n",
    "        stages=[_models[reg_col] for reg_col in regression_cols]\n",
    "    )\n",
    "    _regression_pipeline_model.write().overwrite().save(str(model_pipeline_path))\n",
    "\n",
    "    return _models, _regression_pipeline_model\n",
    "\n",
    "\n",
    "def load_models():\n",
    "    return {\n",
    "        reg_col: GBTRegressionModel.load(str(model_path / reg_col))\n",
    "        for reg_col in regression_cols\n",
    "    }, PipelineModel.load(str(model_pipeline_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494f3680",
   "metadata": {},
   "source": [
    "### Loading or Creating the Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40bf0ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 1:>                                                          (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loaded\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    matches, preprocessing_pipeline_model = load_training_data()\n",
    "    print(\"data loaded\")\n",
    "\n",
    "except:\n",
    "    matches, preprocessing_pipeline_model = create_training_data()\n",
    "    print(\"data created and saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177ad413",
   "metadata": {},
   "source": [
    "### Splitting the Data and Saving the Test Set\n",
    "The test set is saved to be used in the Kafka demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4b2171b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/08/13 23:33:30 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "matches_train, matches_test = matches.randomSplit([0.9, 0.1], 42)\n",
    "\n",
    "matches_test.write.save(str(input_path / \"test_input\"), mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a1ff09",
   "metadata": {},
   "source": [
    "### Loading or creating the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa45fa66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.util.SizeEstimator$ (file:/usr/local/spark/spark-3.3.0-bin-hadoop3/jars/spark-core_2.12-3.3.0.jar) to field java.math.BigInteger.mag\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.util.SizeEstimator$\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models and pipeline loaded\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    models, regression_pipeline_model = load_models()\n",
    "    print(\"models and pipeline loaded\")\n",
    "\n",
    "except:\n",
    "    models, regression_pipeline_model = create_models(matches_train)\n",
    "    print(\"models and pipeline created and saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebe6db2",
   "metadata": {},
   "source": [
    "## 3. Application of the Models Created"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264413a6",
   "metadata": {},
   "source": [
    "### Prediction function\n",
    "this function applies all of the regression models and creates 3 new columns for the overall match results\n",
    "- ```teamPTS_prediction``` - the sum of the points in all quarters predicted of the home team\n",
    "- ```opptPTS_prediction``` - the sum of the points in all quarters predicted of the away team\n",
    "- ```winner_prediction``` - simple function of ```>=```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba2cac92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_infer_results(df):\n",
    "    _predictions = regression_pipeline_model.transform(df)\n",
    "\n",
    "    # Extract columns related to predictions for both teams and opponents.\n",
    "    prediction_cols = [f\"{reg_col}_prediction\" for reg_col in regression_cols]\n",
    "\n",
    "    # Filter out columns specific to each team's and opponent's predictions.\n",
    "    team_pred_cols = [col for col in prediction_cols if col.startswith(\"team\")]\n",
    "    oppt_pred_cols = [col for col in prediction_cols if col.startswith(\"oppt\")]\n",
    "\n",
    "    for pred_col in prediction_cols:\n",
    "        _predictions = _predictions.withColumn(pred_col, F.col(pred_col).cast(\"int\"))\n",
    "\n",
    "    # Compute the total predicted scores for both teams and opponents.\n",
    "    # Produces the classified jobs batch to topics\n",
    "    _predictions = _predictions.withColumn(\n",
    "        \"teamPTS_prediction\", sum(_predictions[col] for col in team_pred_cols)\n",
    "    )\n",
    "    _predictions = _predictions.withColumn(\n",
    "        \"opptPTS_prediction\", sum(_predictions[col] for col in oppt_pred_cols)\n",
    "    )\n",
    "    _predictions = _predictions.withColumn(\n",
    "        \"winner_prediction\",\n",
    "        F.when(\n",
    "            _predictions[\"teamPTS_prediction\"] >= _predictions[\"opptPTS_prediction\"],\n",
    "            _predictions[\"teamAbbr\"],\n",
    "        ).otherwise(_predictions[\"opptAbbr\"]),\n",
    "    )\n",
    "\n",
    "    return _predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec846ca0",
   "metadata": {},
   "source": [
    "### Training Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd0bc531",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/08/13 23:33:43 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "23/08/13 23:33:43 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n",
      "teamPTS1:\n",
      "\trmse - 4.65109159888563\n",
      "\tmae - 3.6658163265306123\n",
      "\tvar - 10.126509787588457\n",
      "teamPTS2:\n",
      "\trmse - 4.549192572448928\n",
      "\tmae - 3.639030612244898\n",
      "\tvar - 9.119528646917944\n",
      "teamPTS3:\n",
      "\trmse - 4.886205071423015\n",
      "\tmae - 3.8520408163265305\n",
      "\tvar - 10.632963804143827\n",
      "teamPTS4:\n",
      "\trmse - 4.528537629436736\n",
      "\tmae - 3.6403061224489797\n",
      "\tvar - 10.264328339754108\n",
      "opptPTS1:\n",
      "\trmse - 4.727929391026332\n",
      "\tmae - 3.766581632653061\n",
      "\tvar - 8.908137234485867\n",
      "opptPTS2:\n",
      "\trmse - 4.7949005650348395\n",
      "\tmae - 3.7818877551020407\n",
      "\tvar - 9.703469908371572\n",
      "opptPTS3:\n",
      "\trmse - 4.582158167216377\n",
      "\tmae - 3.5982142857142856\n",
      "\tvar - 10.144674419512294\n",
      "opptPTS4:\n",
      "\trmse - 4.47113759893066\n",
      "\tmae - 3.559948979591837\n",
      "\tvar - 11.606539267492606\n",
      "teamPTS:\n",
      "\trmse - 5.529835588211738\n",
      "\tmae - 3.88265306122449\n",
      "\tvar - 135.9484915139453\n",
      "opptPTS:\n",
      "\trmse - 5.029885177413017\n",
      "\tmae - 3.559948979591837\n",
      "\tvar - 132.7618912041938\n",
      "\n",
      "accuracy (final result) - 0.31505102040816324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = predict_and_infer_results(matches_test)\n",
    "\n",
    "resultStr = StringIO(\"\")\n",
    "\n",
    "for reg_col in regression_cols + [\"teamPTS\", \"opptPTS\"]:\n",
    "    evaluator = RegressionEvaluator(\n",
    "        labelCol=reg_col, predictionCol=f\"{reg_col}_prediction\"\n",
    "    )\n",
    "\n",
    "    predictions = predictions.withColumn(\n",
    "        f\"{reg_col}_prediction\", F.col(f\"{reg_col}_prediction\").cast(\"double\")\n",
    "    )\n",
    "\n",
    "    predictions = predictions.withColumn(\n",
    "        f\"{reg_col}_prediction\", F.col(f\"{reg_col}_prediction\").cast(\"double\")\n",
    "    )\n",
    "\n",
    "    print(f\"{reg_col}:\", file=resultStr)\n",
    "    for metric_name in [\"rmse\", \"mae\", \"var\"]:\n",
    "        evaluator.setMetricName(metric_name)\n",
    "        print(f\"\\t{metric_name} - {evaluator.evaluate(predictions)}\", file=resultStr)\n",
    "\n",
    "predictions = predictions.withColumn(\n",
    "    \"winner\",\n",
    "    F.when(predictions[\"result\"] == \"Win\", predictions[\"teamAbbr\"]).otherwise(\n",
    "        predictions[\"opptAbbr\"]\n",
    "    ),\n",
    ")\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"winner_indexed\",\n",
    "    predictionCol=\"winner_prediction_indexed\",\n",
    "    metricName=\"accuracy\",\n",
    ")\n",
    "\n",
    "for c in [\"winner\", \"winner_prediction\"]:\n",
    "    predictions = (\n",
    "        StringIndexer(inputCol=c, outputCol=f\"{c}_indexed\")\n",
    "        .fit(predictions)\n",
    "        .transform(predictions)\n",
    "    )\n",
    "\n",
    "print(f\"\\naccuracy (final result) - {evaluator.evaluate(predictions)}\", file=resultStr)\n",
    "\n",
    "print(resultStr.getvalue())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbafdc88",
   "metadata": {},
   "source": [
    "**The accuracy is worse than in the original notebook**. \n",
    "\n",
    "One main reason may be the cause:<br>\n",
    "Unlike in the original notebook, our models ignore the results of the other quarters when predicting a certain quarter, and thus an incorrect assumption is being made - that the results are independent from each other.<br>\n",
    "An additional cause may be the error accumulation when summing the different predictions of each quarter (this can be seen in the variance of ```teamPTS``` and ```opptPTS```)<br>\n",
    "Sure, we could've built a classification model to just predict who wins, but that should be derived from the points per quarter!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6446a5",
   "metadata": {},
   "source": [
    "## 4. Data Streaming Using Kafka"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f0c4a9",
   "metadata": {},
   "source": [
    "```produce_matches``` - assuming the ```batch_df``` is already after preprocessing, the function applies the prediction function defined above, formats the results into a single message and sends the message to a Kafka topic named \"nba\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4813744f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_matches(batch_df, batch_id):\n",
    "    # Transform the incoming batch using a pre-trained regression model.\n",
    "\n",
    "    predictions = predict_and_infer_results(batch_df)\n",
    "\n",
    "    for match in predictions.rdd.collect():\n",
    "        message = (\n",
    "            f'match {match[\"gameId\"]}: {match[\"teamAbbr\"]} vs {match[\"opptAbbr\"]}\\n'\n",
    "            + f'    Q1 predicted scores:    {match[\"teamPTS1_prediction\"]} - {match[\"opptPTS1_prediction\"]}\\n'\n",
    "            + f'    Q2 predicted scores:    {match[\"teamPTS2_prediction\"]} - {match[\"opptPTS2_prediction\"]}\\n'\n",
    "            + f'    Q3 predicted scores:    {match[\"teamPTS3_prediction\"]} - {match[\"opptPTS3_prediction\"]}\\n'\n",
    "            + f'    Q4 predicted scores:    {match[\"teamPTS4_prediction\"]} - {match[\"opptPTS4_prediction\"]}\\n'\n",
    "            + f'    total predicted scores: {match[\"teamPTS_prediction\"]} - {match[\"opptPTS_prediction\"]}\\n'\n",
    "            + f'    predicted winner:       {match[\"winner_prediction\"]}\\n'\n",
    "        )\n",
    "\n",
    "        PRODUCER.produce(\"nba\", value=message)\n",
    "        PRODUCER.flush()\n",
    "\n",
    "        sleep(0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473d48dc",
   "metadata": {},
   "source": [
    "```consume_matches``` - the function continuously polls a Kafka consumer for new messages from a specified topic. When a new message is received, it decodes the message from bytes to a string and appends it to a text file named after the topic. In case of any exceptions, they're printed to the console. The consumer is always closed in the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1bf5765c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def consume_matches(consumer, topic):\n",
    "    try:\n",
    "        while consumer_active:\n",
    "            # Polls for new messages\n",
    "            message = consumer.poll(timeout=3.0)\n",
    "\n",
    "            if message is not None:\n",
    "                # Saves the message to file\n",
    "                message = message.value().decode(\"utf-8\")\n",
    "                with open(topic + \".txt\", \"a\") as file:\n",
    "                    file.write(message)\n",
    "\n",
    "            # sleep(0.1)\n",
    "\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "\n",
    "    finally:\n",
    "        # Closes the consumer to commit final offsets\n",
    "        consumer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54d6103",
   "metadata": {},
   "source": [
    "### Producer-Consumer Configuration\n",
    "Here we set up configurations for a Kafka producer and consumer, and initialize them.<br>\n",
    "The ```consume_matches``` function is set to run on a separate thread, which starts immediately, to continuously consume messages from the \"nba\" topic without blocking other operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bcb3c789",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%4|1691959936.437|CONFWARN|rdkafka#producer-1| [thrd:app]: Configuration property group.id is a consumer property and will be ignored by this producer instance\n",
      "%4|1691959936.437|CONFWARN|rdkafka#producer-1| [thrd:app]: Configuration property auto.offset.reset is a consumer property and will be ignored by this producer instance\n"
     ]
    }
   ],
   "source": [
    "CONFIGURATIONS = {\n",
    "    \"bootstrap.servers\": \"localhost:9092\",  # Kafka's server address.\n",
    "    \"group.id\": \"NBA\",  # Consumer group ID for the Kafka consumer.\n",
    "    \"auto.offset.reset\": \"smallest\",  # Determines where the consumer starts reading messages.\n",
    "}\n",
    "PRODUCER = Producer(\n",
    "    CONFIGURATIONS\n",
    ")  # Initializes a Kafka producer with the specified configurations.\n",
    "CONSUMER = Consumer(CONFIGURATIONS)  # Similarly, initializes a Kafka consumer.\n",
    "\n",
    "consumer_active = (\n",
    "    True  # Flag to control the while loop in the consume_matches function.\n",
    ")\n",
    "\n",
    "\n",
    "CONSUMER.subscribe([\"nba\"])  # Subscribes the consumer to the 'nba' topic.\n",
    "\n",
    "consumer_thread = Thread(target=consume_matches, args=(CONSUMER, \"nba\"))\n",
    "consumer_thread.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa568cf3",
   "metadata": {},
   "source": [
    "### Streaming the Test Data as a Demonstration\n",
    "The code attempts to read and stream the test input that was saved before, and for each batch of the stream calls the ```produce_matches``` function. If there's any issue (like a streaming error), it prints the problem and safely stops the background consumer thread, ```consume_matches```, which was started earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb26453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/08/13 23:52:20 WARN ResolveWriteToStream: Temporary checkpoint location created which is deleted normally when the query didn't fail: /tmp/temporary-23e6a27d-7e41-475c-a2d9-a6cf0d538add. If it's required to delete it under any circumstances, please set spark.sql.streaming.forceDeleteTempCheckpointLocation to true. Important to know deleting temp checkpoint folder is best effort.\n",
      "23/08/13 23:52:20 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    test_df = spark.readStream.schema(matches_test.schema).parquet(\n",
    "        str(input_path / \"test_input\")\n",
    "    )\n",
    "\n",
    "    test_stream = test_df.writeStream.foreachBatch(produce_matches).start()\n",
    "\n",
    "    test_stream.awaitTermination()\n",
    "\n",
    "except Exception as ex:\n",
    "    print(ex)\n",
    "    # Stop the consume_matches thread by setting the controlling flag to False.\n",
    "    consumer_active = False\n",
    "    # Wait for the consumer_thread to finish.\n",
    "    consumer_thread.join()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
